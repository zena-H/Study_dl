{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기울기 소실 문제와 활성화 함수\n",
    "\n",
    "오차 역전파의 문제 \n",
    "- 출력층으로부터 하나씩 되돌아가며 각 층의 가중치를 수정하는 방법이지만 층이 늘어나면서 역전파를 통해 전달되는 기울기의 값이 점점 작아져 기울기 소실(vanishing gradient) 문제 발생\n",
    "\n",
    "- 이를 해결하고자 활성화 함수를 시그모이드가 아닌 여러 함수로 대체하기 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼볼릭 탄젠트 함수\n",
    "- 시그모이드 함수의 범위를 -1 ~ 1로 확장\n",
    "- 하지만 여전히 1보다 작은 값이 존재하므로 기울기 소실 문제는 사라지지 않음\n",
    "- f(x) = tan h (x)\n",
    "\n",
    "렐루 함수(LeLU)\n",
    "- 현재 가장 많이 사용되는 활성화 함수\n",
    "- if x <= 0: return 0\n",
    "- else: return x\n",
    "- 이 방법을 사용하면 x가 0보다 크기만 하면 미분값은 1\n",
    "\n",
    "소프트플러스(softplus) 함수\n",
    "- LeLU 함수의 0이 되는 지점을 완화함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 속도와 정확도 문제를 해결하는 고급 경사 하강법\n",
    "\n",
    "- 확률적 경사 하강법(Stochastic Gradient Descent, SGD)\n",
    "    - 경사 하강법은 불필요하게 많은 계산량으로 속도를 느리게 할 뿐 아니라 최적 해를 찾기 전에 최적화 과정이 멈출 수도 있음\n",
    "    - 이러한 단점을 보완하기 위해 전체 데이터가 아닌 랜덤하게 추출한 일부 데이터를 사용하여 더 빨리, 자주 업데이트 가능\n",
    "    - 중간 결과의 진폭이 크고 불안정해 보일수는 있으나 빠르고 최적 해에 근사한 값을 찾아낸다는 장점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모멘텀(momentum)\n",
    "    - 경사 하강법과 마찬가지로 매번 ㄱ디울기를 구하지만, 이를 통해 오차를 수정하기 전 바로 앞 수정 값과 방향(+, -)를 참고하여 같은 방향으로 일정한 ㅣ율만 수정되게 하는 방법"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
