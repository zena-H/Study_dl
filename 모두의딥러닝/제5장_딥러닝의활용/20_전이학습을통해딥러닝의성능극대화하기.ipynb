{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20_전이학습을통해딥러닝의성능극대화하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiXyycUPbHQVN3aTbnpNT+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "전이학습(transfer learning) : 방대한 자료를 통해 미리 학습한 가중치(weight) 값을 가져와 프로젝트에 활용하는 것"
      ],
      "metadata": {
        "id": "TDH3xKmzuG72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 소규모 데이터셋으로 만드는 강력한 학습 모델\n",
        "\n",
        "지도 학습(supervised learning) : 폐암환자 생존율, 피마인디언 당뇨, MNIST 등 값을 지정하고 학습\n",
        "\n",
        "비지도 학습(unsupervised learning) : GAN, AutoEncoder 등 주어진 데이터의 특성을 찾도록 학습\n"
      ],
      "metadata": {
        "id": "bL6VkC5-uWoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuRjp_eQt_FU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "\"\"\"\n",
        "- rescale : 주어진 이미지 크기를 바꿔줌. 1./255 -> 0~255의 RGB를 0~1 사이의 값으로 바꾸어줌, 학습이 빨라짐\n",
        "- horizontal_flip, vertical_flip : 주어진 이미지를 수평 또는 수직으로 뒤집음\n",
        "- zoom_range : 정해진 범위 내에서 축소, 확대\n",
        "- width_shift, height_shift : 정해진 범위 안에서 수평 또는 수직으로 랜덤하게 평행 이동시킴\n",
        "- rotation_range : 정해진 각도만큼 이미지를 회전시킴\n",
        "- shear_range : 좌표 하나를 고정시키고 다른 몇개의 좌표를 이동시키는 변환\n",
        "- fill_mode : 이미지를 축소 또는 회전하거나 이동할때 생기는 빈 공간을 어떻게 채울지 결정. nearest 옵션을 선택하면 가장 비슷한 색으로 채워짐\n",
        "\"\"\"\n",
        "traln_datagen = ImageDataGenrator(rescale = 1. / 255,\n",
        "                                  horizontal_flip = True,\n",
        "                                  width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1,\n",
        "                                  fill_mode = 'nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './train',                     # train 데이터셋이 저장된 폴더\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'binary'   \n",
        ")\n",
        "\n",
        "# 테스트 셋은 이미지 부풀리기 과정을 진행하지 않음\n",
        "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    './test',\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "# 앞서 배운 CNN 모델을 만들어 적용하기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape = (150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(learning_rate = 2e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# 모델 실행\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 20,\n",
        "    validation_data = test_generator,\n",
        "    validation_steps = 4\n",
        ")\n",
        "\n",
        "# 결과를 그래프로 표현하는 부분\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, acc, marker = '.', c = 'red', label = 'Trainset_acc')\n",
        "plt.plot(x_len, val_acc, marker = '.', c = 'lightcoral', label = 'Testset_acc')\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker = '.', c = 'conflowerblue', label = 'Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
        "\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss/acc')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 전이 학습으로 모델 성능 극대화하기\n",
        "\n",
        "VGGNet : 옥스포드의 연구팀 VGG에서 개발된 모델(층에 따라 VGG16, VGG19 등으로 불림)"
      ],
      "metadata": {
        "id": "oZiPOByz0QGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Input, models, layers, optimizers, metrics\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.compat.v1.set_random_seed(3)\n",
        "\n",
        "train_datagen = ImageDataGenrator(rescale = 1. /255,\n",
        "                                  horizontal_flip = True,\n",
        "                                  width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1,\n",
        "                                  fill_mode = 'nearest')\n",
        "\n",
        "train_generator = train_datagent.flow_from_directory(\n",
        "    'train',\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1. / 255,\n",
        "                                  horizontal_flip = True,\n",
        "                                  width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1,\n",
        "                                  fill_mode = 'nearest')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'test',\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "transfer_model = VGG16(weights = 'imagenet',\n",
        "                       include_top = False,\n",
        "                       input_shape = (150, 150, 3))\n",
        "transfer_model.trainable = False\n",
        "transfer_model.summary()\n",
        "\n",
        "finetune_model = models.Sequential()\n",
        "finetune_model.add(transfer_model)\n",
        "finetune_model.add(Flatten())\n",
        "finetune_model.add(Dense(64, activation = 'relu'))\n",
        "finetune_model.add(Dense(2, activation = 'softmax'))\n",
        "finetune_model.summary()\n",
        "\n",
        "finetune_model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "                       optimizer = optimizers.Adam(learning_rate = 2e-4),\n",
        "                       metrics = ['accuracy'])\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator,\n",
        "                                       steps_per_epoch = 100,\n",
        "                                       epochs = 20,\n",
        "                                       validation_data = test_generator,\n",
        "                                       validation_steps = 4)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, acc, marker = '.', c = 'red', label = 'Trainset_acc')\n",
        "plt.plot(x_len, val_acc, marker = '.', c = 'lightcoral', label = 'Testset_acc')\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker = '.', c = 'cornflowerblue', label = 'Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
        "\n",
        "plt.legend('upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss/acc')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jq2-fYvm0TgT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}